import numpy as np
import random as rand
from scipy.optimize import minimize
from scipy import stats
from scipy.stats import uniform
import matplotlib.pyplot as plt

#Генерация распределения
tau = rand.uniform(0, 1)
mu1 = rand.uniform(0,1)
mu2 = rand.uniform(0, 1)
sigma2 = rand.uniform(0, 5)
sigma1 = rand.uniform(0, 5)
print(tau, mu1, mu2, sigma1, sigma2)
n = 100000
n_n1 = int(tau * n)
n_n2 = n - n_n1

x_n1 = np.random.normal(mu1, sigma1, n_n1)
x_n2 = np.random.normal(mu2, sigma2, n_n2)
x = np.concatenate((x_n1, x_n2))

#Начальные значения параметров
_mu1 = 0.5
_mu2 = 0.5
_sigma1 = 2.5
_sigma2 = 2.5
_tau = 0.5
_x0 = [_tau, _mu1, _mu2, _sigma1, _sigma2]
_x0 = np.asarray(_x0)
# print('guess values:', _x0)
def max_likelihood(x, tau, mu1, mu2, sigma1, sigma2, rtol=1e-3):
    f1 = stats.norm.pdf(x, loc=mu1, scale=sigma1)
    f2 = stats.norm.pdf(x, loc=mu2, scale=sigma2)
    f = (tau * f1 + (1 - tau) * f2)
    return -np.sum(np.log(f))
bnds = ((0,1),(0,1),(0,1),(0,5),(0,5))
z = minimize(lambda x0:max_likelihood(x, *x0),_x0, bounds = bnds, tol=1e-4)
print(z)

#EM метод
def t(x, tau, mu1, sigma1, mu2, sigma2):
        t_n = tau / np.sqrt(2 * np.pi * sigma1) * np.exp(-0.5 * (x - mu1) ** 2 / sigma1)
        t_u = (1-tau) / np.sqrt(2 * np.pi * sigma2) * np.exp(-0.5 * (x - mu2) ** 2 / sigma2)
        return np.vstack((t_n / (t_u + t_n), t_u / (t_u + t_n)))

def theta(x, old):
        t_n, t_u = t(x, *old)
        tau = np.sum(t_n) / np.sum(t_n + t_u)
        mu1 = np.sum(t_n * x) / np.sum(t_n)
        mu2 = np.sum(t_u * x) / np.sum(t_u)
        sigma1 = np.sum(t_u * (x - mu2) ** 2) / np.sum(t_u)
        sigma2 = np.sum(t_u * (x - mu2) ** 2) / np.sum(t_u)
        return tau, mu1, sigma1, mu2, sigma2
def em_double_gauss(x, tau, mu1, sigma1, mu2, sigma2, rtol):
    old = [tau, mu1, sigma1, mu2, sigma2]
    while True:
        new = theta(x, old)
        old = new
        if np.allclose(new, old, rtol=rtol): break

    return new


print('em double gauss',em_double_gauss(x, _tau,_mu1, _sigma1, _mu2, _sigma2, rtol=1e-4))
